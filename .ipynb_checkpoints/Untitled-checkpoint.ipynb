{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0979cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain\n",
    "# pip install chromadb\n",
    "# pip install sentence-transformers\n",
    "# pip install auto-gptq\n",
    "# pip install einops\n",
    "# pip install unstructured\n",
    "# pip install transformers\n",
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783118f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from auto_gptq import AutoGPTQForCausalLM\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoTokenizer , GenerationConfig , TextStreamer , pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f782f5c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5bb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_dir =Path('skyscanner')\n",
    "question_dir.mkdir(exist_ok=True , parents = True)\n",
    "\n",
    "# writing QnA\n",
    "\n",
    "def write_file (question , answer , file_path):\n",
    "    text = f\"\"\"\n",
    "Q: { question}\n",
    "A: {answer}\n",
    "\n",
    "\"\"\".strip()\n",
    "    with Path (question_dir / file_path).open(\"w\") as text_file:\n",
    "        text_file.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e461d98",
   "metadata": {},
   "source": [
    "# Making Custom QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "442703ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"How do I search for flights on Skyscanner?\" ,\n",
    "    answer= \"\"\"To find flights on Skyscanner, input your departure and arrival information along with travel dates, and then click 'Search.' You'll be presented with a range of flight choices from different airlines and agencies. Utilize filters for further customization, select your preferred flight, and proceed to book directly through the provided options. Alternatively, you can use the 'Explore everywhere' feature to discover various destinations and their prices across multiple travel sites.\n",
    "    \"\"\".strip(),\n",
    " file_path = \"question_1.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f16bf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"How do I search for multiple destinations?\" ,\n",
    "    answer= \"\"\"\n",
    "For a multi-city search on Skyscanner, simply click the 'Multi-city' button at the start of your search. From there, you can input your desired travel dates, destinations, and additional flights. Although the price alert option isn't currently available for multi-city searches, the Skyscanner team is actively working on introducing this feature in the near future. To learn more about how to navigate this new feature, refer to the provided article. Skyscanner values user feedback to enhance their services, and you can share your thoughts by clicking the 'Contact Us' button below the article.\n",
    "    \"\"\".strip(),\n",
    " file_path = \"question_2.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "157baeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"How do I search for flights on Skyscanner?\" ,\n",
    "    answer= \"\"\"Skyscanner's default search setting is configured for return flights, but switching to one-way flights is straightforward. Whether you're using the website, mobile site, or app, you can easily search for one-way flights by choosing the 'one way' option located above the 'From' field, where you enter the departure airport. If you wish to revert to searching for return flights, you can do so by re-selecting the 'Return' option or by clicking within the return date field. This will allow you to resume searching for return flight options seamlessly. Skyscanner's user-friendly interface ensures a smooth transition between these search modes.\"\"\".strip(),\n",
    " file_path = \"question_3.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd871837",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"What does it mean when I see ‘Non-protected transfers’ or ‘Self-transfer flight’ on Skyscanner?\" ,\n",
    "    answer= \"\"\"At Skyscanner, our aim is to enhance your travel experience to the fullest, and we recognize that achieving savings on flights contributes to happier travelers. When you initiate a flight search, we present a wide array of diverse options, all designed to ensure you receive the utmost value for your money. However, there's a significant caveat that deserves attention – and we've highlighted it for emphasis. A number of these more affordable choices do come with associated risks, which is why they are priced lower in the first place. Prior to finalizing your booking, our goal is to provide you with the necessary insights to comprehend the commitments you're making. While some of this information might seem intricate, we're committed to delivering the clearest explanations possible.\"\"\".strip(),\n",
    " file_path = \"question_4.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2790891a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"How do I change my settings to english ?\" ,\n",
    "    answer= \"\"\"Skyscanner is proud to offer its website in over 30 languages, ensuring accessibility for a diverse global audience. To adjust the language setting on our desktop website, simply locate the flag icon in the top menu and click on it. From the ensuing drop-down list, select your desired language. If you wish to switch directly to English, be on the lookout for the 'Switch to English' button. For the mobile website, tap on the designated area, followed by the flag icon. A dropdown list will emerge, allowing you to select your preferred language. The 'Switch to English' button serves as a direct shortcut if you want to switch languages immediately. Within the Skyscanner app, access the language settings by navigating to the appropriate section. From there, select your desired language, enabling a seamless linguistic transition for your user experience.\"\"\".strip(),\n",
    " file_path = \"question_5.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69d5efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"Why have I been blocked from accessing the Skyscanner website??\" ,\n",
    "    answer= \"\"\"Skyscanner's websites encounter a substantial volume of bot-driven scraping activity daily, which adversely impacts the quality of service we strive to offer. To counter this, we've implemented a bot-blocking solution designed to verify that users interact with the website in a conventional manner. At times, genuine users might find themselves incorrectly flagged as bots due to various potential reasons. These include scenarios such as utilizing a VPN that was blocked due to previous excessive bot traffic, navigating the site at an unusually rapid pace surpassing our rate limits, employing browser plugins that interfere with our website's user interaction, or utilizing an automated browser. If you find yourself blocked while using our services normally, kindly provide us with your IP address (which you can find at websites like http://www.whatismyip.com/), the specific website you were accessing (e.g., www.skyscanner.net), and the date/time when the issue occurred. You can share this information with us through the \"Contact Us\" button, and we'll promptly investigate and resolve the matter.\"\"\".strip(),\n",
    "file_path = \"question_6.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "580e0405",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \" When I get redirected to a provider’s website the currency is different?\" ,\n",
    "    answer= \"\"\"Skyscanner grants the flexibility to select your desired currency for price viewing and flight comparisons. However, some airline and travel agent websites might limit the currencies they display or accept for payment. Should these flights be visible on Skyscanner, booking them is typically feasible. It's important to consider that if you choose to pay for a flight in a currency differing from your bank or credit card issuer's, the currency conversion will be managed by them. This could involve an alternate exchange rate compared to Skyscanner's and potential commission charges. For accurate information on the applicable exchange rate, it's recommended to directly contact your bank, ensuring you're well-informed about potential discrepancies in currency conversion expenses.\"\"\".strip(),\n",
    " file_path = \"question_7.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716753fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"Where is my booking confirmation?\" ,\n",
    "    answer= \"\"\"Following your travel purchase, a booking confirmation should be sent to you via email by the respective company. Do remember to check your spam/junk mail folder, as occasionally, these confirmations might end up there. If you're unable to locate the confirmation, consider reaching out to the company you made the purchase from to gather more information. To identify the appropriate contact, refer to the company name listed alongside the charge on your bank account.\"\"\".strip(),\n",
    " file_path = \"question_8.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "467fbbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"Were you charged by an airline or travel agent?\" ,\n",
    "    answer= \"\"\"Our platform encompasses an extensive array of options, connecting you with thousands of travel agencies, airlines, hotels, and car rental companies, collectively referred to as our \"partners.\" In cases where you've been directed to a partner's website during your search or booking process, it's advisable to establish direct communication with them to address any specific concerns or queries you may have regarding your experience.\"\"\".strip(),\n",
    " file_path = \"question_9.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f907158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"How do I contact customer service about my booking?\" ,\n",
    "    answer= \"\"\"If you need to contact, phone or email customer service about your booking, it's important first to know who you bought from. The best way to find out who you bought from is to check your confirmation email, or check your bank or card statement for a company name.There are 1000s of travel agencies, airlines, hotels and car hire companies that you can buy from through our site and app. We call them \"partners\". When you buy from them, they will take your payment (you'll see their name on your bank or credit card statement), contact you to confirm your booking, and provide any help or support you might need.If you bought from one of these partners, you'll need to contact them as they have all the info about your booking. We unfortunately don't have any access to bookings you made with them. You'll find their customer service contact number, email address and other ways to get in touch in your booking confirmation email. Alternatively, you can use the following link to find their contact details.\"\"\".strip(),\n",
    " file_path = \"question_10.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84420cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \" How do I find out if my booking has gone through?\" ,\n",
    "    answer= \"\"\"After making a booking with an airline or travel agent, they will typically send you a confirmation email and initiate the transaction charge on your card or bank account. Keep in mind that these confirmation emails might occasionally be redirected to your spam/junk mail folder, warranting a check there. If the confirmation is still elusive or if uncertainties persist, it's advisable to reach out to the selling company directly for comprehensive information about your booking. Our platform offers access to a diverse range of travel agencies, airlines, hotels, and car rental firms for your purchases, and in cases where you've transacted with these partners, direct contact with them is recommended, as they possess all the pertinent details regarding your booking.\"\"\".strip(),\n",
    " file_path = \"question_11.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fe1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"How do I change or cancel my booking?\" ,\n",
    "    answer= \"\"\"For inquiries regarding changes, cancellations, refunds, and all aspects of your bookings, it's essential to directly contact the company from which you purchased your travel, as they hold the comprehensive information needed to assist you. Our platform provides access to a wide range of travel agencies, airlines, hotels, and car rental companies for your convenience. When you make a purchase from these travel partners through our site and app, they handle your payment (visible on your bank or credit card statement), confirm your booking, and offer necessary support. If your transaction involves these partners, reaching out to them is necessary, as they possess the booking details. It's important to note that we lack access to bookings made directly through them.\"\"\".strip(),\n",
    " file_path = \"question_12.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ba78fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"Where is my booking confirmation?\" ,\n",
    "    answer= \"\"\"After purchasing your travel, you should receive a booking confirmation via email from the respective company. It's advisable to check your spam/junk mail folder, as occasionally these confirmations might be directed there. If you're still unable to locate the confirmation, reaching out to the purchasing company is recommended to gain clarity on the situation. To identify the appropriate contact, cross-reference the company name listed alongside the charge on your bank account, as this will guide you toward the right point of contact for resolution.\"\"\".strip(),\n",
    " file_path = \"question_13.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3820c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_file(\n",
    "    question = \"Where can I view and manage the price alerts I have set up?\" ,\n",
    "    answer= \"\"\"To manage the price alerts you've set up, log in to your Skyscanner account. If you didn't initially create an account, follow the process and click 'forgotten your password?' on the account screen. On the desktop site, log in by clicking 'Log in' at the top; on the mobile site and app, tap and then tap 'Log in'. After logging in on desktop or mobile, access the 'Account' option to navigate to the Price Alert Management section. Here, you can view your active alerts, check the latest prices, initiate immediate searches, stop alerts, or create new ones. On the app, tap the top left corner, then 'Recent searches and Price Alerts' to effectively manage your alerts.\"\"\".strip(),\n",
    " file_path = \"question_14.txt\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7f9f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name_or_path = \"TheBloke/Nous-Hermes-13B-GPTQ\"\n",
    "# model_basename = \"nous-hermes-13b-GPTQ-4bit-128g.no-act.order\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path,use_fast=False)\n",
    "\n",
    "# model = AutoGPTQForCausalLM.from_quantized(\n",
    "#      model_name_or_path,\n",
    "#      model_basename=model_basename,\n",
    "#      use_safetensors=True,\n",
    "#      trust_remote_code=True,\n",
    "#      device='cpu'\n",
    "    \n",
    "# )\n",
    "# generation_config = GenerationConfig.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1204f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"NousResearch/Nous-Hermes-13b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07e860d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea252966b9a84b5ca55402b172237335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/26.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 283115520 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m----> 2\u001b[0m translator \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion-answering\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNousResearch/Nous-Hermes-13b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\__init__.py:807\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    806\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[1;32m--> 807\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    808\u001b[0m         model,\n\u001b[0;32m    809\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[0;32m    810\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[0;32m    811\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[0;32m    812\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    815\u001b[0m     )\n\u001b[0;32m    817\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[0;32m    818\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\pipelines\\base.py:267\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 267\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    269\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\modeling_utils.py:2876\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2873\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[0;32m   2875\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m-> 2876\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2878\u001b[0m \u001b[38;5;66;03m# Check first if we are `from_pt`\u001b[39;00m\n\u001b[0;32m   2879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_keep_in_fp32_modules:\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:736\u001b[0m, in \u001b[0;36mLlamaForCausalLM.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:566\u001b[0m, in \u001b[0;36mLlamaModel.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[1;32m--> 566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([LlamaDecoderLayer(config) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:566\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[1;32m--> 566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([\u001b[43mLlamaDecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)])\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:381\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mhidden_size\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m LlamaAttention(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm \u001b[38;5;241m=\u001b[39m LlamaRMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:198\u001b[0m, in \u001b[0;36mLlamaMLP.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mintermediate_size\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn \u001b[38;5;241m=\u001b[39m ACT2FN[config\u001b[38;5;241m.\u001b[39mhidden_act]\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 283115520 bytes."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline('question-answering',model=\"NousResearch/Nous-Hermes-13b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f7076f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt-get install git-lfs\n",
    "# !git lfs install\n",
    "\n",
    "# # Then\n",
    "# !git clone https://huggingface.co/facebook/bart-base\n",
    "\n",
    "# from transformers import AutoModel\n",
    "\n",
    "# model = AutoModel.from_pretrained('./bart-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ab6eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=(\"which programming language is more sitable for beginner:python or java?\")\n",
    "prompt = f\"\"\"\n",
    "### instruction :{question}\n",
    "### response:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bf896687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### instruction :which programming language is more sitable for beginner:python or java?\n",
      "### response:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ab3b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'return_tensor': 'pt'} not recognized.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_ids = tokenizer(prompt,return_tensor=\"pt\").input_ids.to(DEVICE)\n",
    "with torch.inference_model():\n",
    "    output = model.generate(inputs_ids,temperature=0.7,max_new_tokens=512)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a41a758e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokenizer\u001b[38;5;241m.\u001b[39mdecode(\u001b[43moutput\u001b[49m[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(output[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d993dc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = TextStreamer(tokenizer,skip_prompt=True,skip_special_tokens=True,use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "350724de",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (741481730.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [62]\u001b[1;36m\u001b[0m\n\u001b[1;33m    generation_config=generation_config,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-generation',\n",
    "                model=model,\n",
    "                max_length = 2048,\n",
    "                temperature=0.5,\n",
    "                top_p=0.95,\n",
    "                streamer=streamer\n",
    "                generation_config=generation_config,\n",
    "                batch_size=1,\n",
    "                repetation_penalty=1.15,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a40b669",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m llm \u001b[38;5;241m=\u001b[39m HuggingFacePipeline(pipeline\u001b[38;5;241m=\u001b[39m\u001b[43mpipe\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46d66ee5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m(prompt)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "response = llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bd38a0",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad16ba2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RepositoryNotFoundError",
     "evalue": "401 Client Error. (Request ID: Root=1-64ebd83f-0086db294f5bbcd76fa3f639;b3fbb119-ae80-4f26-832b-a7fa705a8b5a)\n\nRepository Not Found for url: https://huggingface.co/api/models/embass/sentence-transformer-multilingual-e5-base.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/embass/sentence-transformer-multilingual-e5-base",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43mmodel_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membass/sentence-transformer-multilingual-e5-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43mmodel_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\langchain\\embeddings\\huggingface.py:59\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence_transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     57\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[0;32m     61\u001b[0m )\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:87\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001b[0m\n\u001b[0;32m     83\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cache_folder, model_name_or_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;66;03m# Download from hub with caching\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m         \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence-transformers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mignore_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflax_model.msgpack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrust_model.ot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtf_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m'\u001b[39m)):    \u001b[38;5;66;03m#Load as SentenceTransformer model\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(model_path)\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sentence_transformers\\util.py:442\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(repo_id, revision, cache_dir, library_name, library_version, user_agent, ignore_files, use_auth_token)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m use_auth_token:\n\u001b[0;32m    440\u001b[0m     token \u001b[38;5;241m=\u001b[39m HfFolder\u001b[38;5;241m.\u001b[39mget_token()\n\u001b[1;32m--> 442\u001b[0m model_info \u001b[38;5;241m=\u001b[39m \u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m storage_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    445\u001b[0m     cache_dir, repo_id\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    446\u001b[0m )\n\u001b[0;32m    448\u001b[0m all_files \u001b[38;5;241m=\u001b[39m model_info\u001b[38;5;241m.\u001b[39msiblings\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\hf_api.py:1678\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[1;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m-> 1678\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1679\u001b[0m d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m   1680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n",
      "File \u001b[1;32mc:\\users\\subra\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\huggingface_hub\\utils\\_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m# 401 is misleading as it is returned for:\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m#    - private and gated repos if user is not authenticated\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m#    - missing repos\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[0;32m    285\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m     )\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m    296\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     )\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-64ebd83f-0086db294f5bbcd76fa3f639;b3fbb119-ae80-4f26-832b-a7fa705a8b5a)\n\nRepository Not Found for url: https://huggingface.co/api/models/embass/sentence-transformer-multilingual-e5-base.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "embedding = HuggingFaceEmbeddings(\n",
    "model_name = \"embass/sentence-transformer-multilingual-e5-base\",\n",
    "model_kwargs ={\"device\":'cpu'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b0b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385b8ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331c12f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6094200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1706c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709ff80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75d386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7c8bd5d",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "254ab086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\"./skyscanner/\",glob=\"**/*txt\")\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "606d3a84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CharacterTextSplitterracterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m \u001b[43mCharacterTextSplitterracterTextSplitter\u001b[49m(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m,chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(documents)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CharacterTextSplitterracterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitterracterTextSplitter(chunk_size=512,chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbb20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "db=Chroma.from_documents(texts,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82368d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.similarity_search(\"flight search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb34823a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f458e06",
   "metadata": {},
   "source": [
    "# Support Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f04ee6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TEMPLATE = \"\"\"\n",
    "### instruction: You're a travelling support agent that is talking to a customer . Use only the caht history and the following information \n",
    "{context}\n",
    "to answer in a helpful manner to the queries . If you don't know the answer - say that you don't know.\n",
    "Keep your replies short , compassionate and informative .\n",
    "{chat_history}\n",
    "### Input:{question}\n",
    "### Response :\"\"\".strip()\n",
    "\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(\n",
    "        self,\n",
    "        text_pipeline:HuggingFacePipeline,\n",
    "        embeddings:HuggingFaceEmbeddings,\n",
    "        documents_sir:Path,\n",
    "        prompt_template:str=DEFAULT_TEMPLATE,\n",
    "        verbrose:bool = False,):\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "        input_variable = [\"context\",\"question\",\"chat_history\"],\n",
    "        template=prompt_template,)\n",
    "        \n",
    "        self.chain =self.create_chain(text_pipeline,prompt,verbrose)\n",
    "        self.db = self.embed_data(documents_dir,embeddings)\n",
    "        \n",
    "    def _create_chain(self,\n",
    "                     text_pipeline:HuggingFacePipeline,\n",
    "                     prompt = PromptTemplate,\n",
    "                     verbrose:bool = False,):\n",
    "        memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        human_prefix=\"##Input\",\n",
    "        ai_prefix = \"### Response\",\n",
    "        output_key=\"answer\",\n",
    "        return_messages=True,\n",
    "\n",
    ")\n",
    "                 \n",
    "        return load_qa_chain(\n",
    "               text_pipeline,\n",
    "               chain_type=\"stuff\",\n",
    "               prompt=prompt,\n",
    "               memory=memory,\n",
    "               verbrose=verbrose)\n",
    "    def _embed_data(\n",
    "         self,documents_dir:Path,embedings:HuggingFaceEmbeddings)->Chroma:\n",
    "        loader =DirectoryLoader(documnet_dir,glob=\"**/*txt\")\n",
    "        documents =loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=512,chunk_overlap=0)\n",
    "        texts = texts_splitter.split_documents(documents)\n",
    "        return Chroma.from_documents(texts,embeddings)\n",
    "    def __call__(self,user_input:str)->str:\n",
    "        docs = self.db.similarity_search(user_input)\n",
    "        return self.chain.run({\"input_documents\":docs,\"questions\":user_input})\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d7befd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m Chatbot(\u001b[43mtranslator\u001b[49m,embeddings,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./skyscanner/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translator' is not defined"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot(translator,embeddings,\"./skyscanner/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb16ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "\n",
    "while True:\n",
    "    user_input=input(\"You: \")\n",
    "    if user_input.lower() in [\"bye\",\"goodbye\"]:\n",
    "        break\n",
    "    answer = Chatbot(user_input)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0a476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ec197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de6f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1ff9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6ff9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10b047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f39da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6f1185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2c7d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
